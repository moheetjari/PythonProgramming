{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment:KNN&NaiveBayesClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMHhelxY9MoklJqGWYsICzk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moheetjari/PythonProgramming/blob/main/Assignment_KNN%26NaiveBayesClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50XHT6gWKLDR"
      },
      "source": [
        "#Classify given data sets\n",
        "#diabets.csv and fruits.txt\n",
        "#using kNN and Naive Bayes classifier models.\n",
        "#Which machine learning model is more suitable for given data and why? Justify your answer.\n",
        "#(Note: Perform data preprocessing wherever required.)\n",
        "\n",
        "#submission instructions:\n",
        "#Take screen shots of coding and prepare one single pdf file and submit online into classroom."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zozmWd6mM2qG"
      },
      "source": [
        "#Load the necessary python libraries.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkXOufPVtlPm"
      },
      "source": [
        "#Load the dataset.\n",
        "df = pd.read_csv('/content/diabetes.csv')\n",
        "\n",
        "#Print the first 5 rows of the dataframe. \n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgwLnqaPt1lb"
      },
      "source": [
        "#Let's observe the shape of the dataframe.\n",
        "#As observed above we have 768 rows and 9 columns. The first 8 columns represent the features and the last column represent the target/label.\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMxxSfepuWcp"
      },
      "source": [
        "#Let's create numpy array for features and target\n",
        "features = df.drop('Outcome',axis=1).values\n",
        "target = df['Outcome'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lSF5Nhrvqbn"
      },
      "source": [
        "#Let's split the data randomly into training and test set.\n",
        "#We will fit/train a classifier on the training set and make predictions on the test set. Then we will compare the predictions with the known labels.\n",
        "#Scikit-learn provides facility to split data into train and test set using train_test_split method.\n",
        "\n",
        "#importing train_test_split\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R69PWGSJGRbX"
      },
      "source": [
        "#It is a best practice to perform our split in such a way that out split reflects the labels in the data. In other words, we want labels to be split in train and test set as they are in the original dataset. So we use the stratify argument.\n",
        "#Also we create a test set of size of about 40% of the dataset.\n",
        "features_train,features_test,target_train,target_test = train_test_split(features,target,test_size=0.4,random_state=42,stratify=target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9blew3fNG-Hx"
      },
      "source": [
        "#Let's create a classifier using k-Nearest Neighbors algorithm.\n",
        "#First let us first observe the accuracies for different values of k.\n",
        "\n",
        "#import KNeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#Setup arrays to store training and test accuracies\n",
        "neighbors = np.arange(1,9)\n",
        "train_accuracy =np.empty(len(neighbors))\n",
        "test_accuracy = np.empty(len(neighbors))\n",
        "\n",
        "for i,k in enumerate(neighbors):\n",
        "    #Setup a knn classifier with k neighbors\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    \n",
        "    #Fit the model\n",
        "    knn.fit(features_train, target_train)\n",
        "    \n",
        "    #Compute accuracy on the training set\n",
        "    train_accuracy[i] = knn.score(features_train, target_train)\n",
        "    \n",
        "    #Compute accuracy on the test set\n",
        "    test_accuracy[i] = knn.score(features_test, target_test) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUE2SMRLIUcl"
      },
      "source": [
        "#Generate plot\n",
        "plt.title('k-NN Varying number of neighbors')\n",
        "plt.plot(neighbors, test_accuracy, label='Testing Accuracy')\n",
        "plt.plot(neighbors, train_accuracy, label='Training accuracy')\n",
        "plt.legend()\n",
        "plt.xlabel('Number of neighbors')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIH827e5Iax7"
      },
      "source": [
        "#We can observe above that we get maximum testing accuracy for k=7. So lets create a KNeighborsClassifier with number of neighbors as 7.\n",
        "#Setup a knn classifier with k neighbors\n",
        "knn = KNeighborsClassifier(n_neighbors=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbobr18OIh7I"
      },
      "source": [
        "#Fit the model\n",
        "knn.fit(features_train,target_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5GpBpnjI1Kt",
        "outputId": "a5a7ebaa-64da-4912-d9e5-3b0873fd578b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Get accuracy. Note: In case of classification algorithms score method represents accuracy.\n",
        "knn.score(features_test,target_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7305194805194806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    }
  ]
}